{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Scrapper for NLP Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import getpass as gp\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https:twitter.com/login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Up Log In\n",
    "\n",
    "sleep(3)\n",
    "\n",
    "# Username\n",
    "username = driver.find_element(By.XPATH, \"//input[@name='text']\")\n",
    "username.send_keys(gp.getpass(prompt='Username:'))\n",
    "\n",
    "# Next Button\n",
    "next_button = driver.find_element(By.XPATH, \"//span[contains(text(),'Next')]\") \n",
    "next_button.click()\n",
    "\n",
    "\n",
    "sleep(3)\n",
    "\n",
    "# Password\n",
    "password = driver.find_element(By.XPATH, \"//input[@name='password']\")\n",
    "password.send_keys(gp.getpass(prompt='Password:'))\n",
    "\n",
    "# Log In Button\n",
    "login_button = driver.find_element(By.XPATH, \"//span[contains(text(),'Log in')]\")\n",
    "login_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Item\n",
    "\n",
    "search_word = \"#G20India\"\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "search_box = driver.find_element(By.XPATH, \"//input[@data-testid='SearchBox_Search_Input']\")\n",
    "search_box.send_keys(search_word)\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Tweets\n",
    "\n",
    "\n",
    "#UserTag = driver.find_element(By.XPATH,\"//div[@data-testid='User-Name']\").text\n",
    "#TimeStamp = driver.find_element(By.XPATH, \"//time\").get_attribute('datetime')\n",
    "#Tweet = driver.find_element(By.XPATH, \"//div[@data-testid='tweetText']\").text\n",
    "#Reply = 0 if (len(driver.find_element(By.XPATH, \"//div[@data-testid='reply']\").text)) == 0 else driver.find_element(By.XPATH, \"//div[@data-testid='reply']\").text\n",
    "#ReTweet = 0 if (len(driver.find_element(By.XPATH, \"//div[@data-testid='retweet']\").text)) == 0 else driver.find_element(By.XPATH, \"//div[@data-testid='retweet']\").text\n",
    "#Like = 0 if (len(driver.find_element(By.XPATH, \"//div[@data-testid='like']\").text)) == 0 else driver.find_element(By.XPATH, \"//div[@data-testid='like']\").text\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "UserTags = []\n",
    "TimeStamps = []\n",
    "Tweets = []\n",
    "Replys = []\n",
    "ReTweets = []\n",
    "Likes = []\n",
    "\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    \n",
    "    CheckLastUniqueCount = len(list(set(Tweets)))\n",
    "    \n",
    "    sleep(5)\n",
    "\n",
    "    articles = driver.find_elements(By.XPATH, \"//article[@data-testid='tweet']\")\n",
    "\n",
    "    for article in articles:\n",
    "        #No TimeStamp means it's an Advertisment\n",
    "        try:\n",
    "            TimeStamp = article.find_element(By.XPATH, \".//time\").get_attribute('datetime')\n",
    "        except NoSuchElementException:\n",
    "            continue\n",
    "        TimeStamps.append(TimeStamp)\n",
    "    \n",
    "        UserTag = article.find_element(By.XPATH,\".//div[@data-testid='User-Name']\").text\n",
    "        UserTags.append(UserTag)\n",
    "    \n",
    "        Tweet = article.find_element(By.XPATH, \".//div[@data-testid='tweetText']\").text\n",
    "        Tweets.append(Tweet)\n",
    "    \n",
    "        Reply = 0 if (len(article.find_element(By.XPATH, \".//div[@data-testid='reply']\").text)) == 0 else article.find_element(By.XPATH, \".//div[@data-testid='reply']\").text\n",
    "        Replys.append(Reply)\n",
    "    \n",
    "        ReTweet = 0 if (len(article.find_element(By.XPATH, \".//div[@data-testid='retweet']\").text)) == 0 else article.find_element(By.XPATH, \".//div[@data-testid='retweet']\").text\n",
    "        ReTweets.append(ReTweet)\n",
    "    \n",
    "        Like = 0 if (len(article.find_element(By.XPATH, \".//div[@data-testid='like']\").text)) == 0 else article.find_element(By.XPATH, \".//div[@data-testid='like']\").text\n",
    "        Likes.append(Like)\n",
    "    \n",
    "    CheckCurrentUniqueCount = len(list(set(Tweets)))\n",
    "    if CheckCurrentUniqueCount > 250 or CheckLastUniqueCount == CheckCurrentUniqueCount:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(UserTags, TimeStamps, Tweets, Replys, ReTweets, Likes), columns=['UserTag', 'TimeStamp', 'Tweet', 'Replies', 'ReTweets', 'Likes'])\n",
    "\n",
    "df.to_csv('Data/'+search_word+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
